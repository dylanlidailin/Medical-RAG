{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f51f7d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunked documents: 116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d9/cgypymwn2tj96mmjdmrs_2xr0000gn/T/ipykernel_33510/177605692.py:38: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved to ./rxnorm_faiss_index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# === Step 1: Load and Clean RxNorm CSV ===\n",
    "df = pd.read_csv(\"rxnorm_enriched_chunks.csv\")\n",
    "df = df.dropna(subset=[\"Text_Chunk\", \"STR\", \"RXCUI\", \"TTY\"])  # remove empty rows\n",
    "\n",
    "# === Step 2: Chunk Texts (optional overlap) ===\n",
    "def chunk_text(text, chunk_size=300, overlap=50):\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        chunk = text[i:i + chunk_size].strip()\n",
    "        if len(chunk) > 50:\n",
    "            chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "chunked_docs = []\n",
    "for _, row in df.iterrows():\n",
    "    chunks = chunk_text(row[\"Text_Chunk\"])\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        metadata = {\n",
    "            \"drug_name\": row[\"STR\"],\n",
    "            \"rxcui\": row[\"RXCUI\"],\n",
    "            \"term_type\": row[\"TTY\"],\n",
    "            \"code\": row.get(\"CODE\", \"\"),\n",
    "            \"source\": row.get(\"SAB\", \"\"),\n",
    "            \"chunk_index\": idx\n",
    "        }\n",
    "        doc = Document(page_content=chunk, metadata=metadata)\n",
    "        chunked_docs.append(doc)\n",
    "\n",
    "print(f\"Total chunked documents: {len(chunked_docs)}\")\n",
    "\n",
    "# === Step 3: Create embeddings ===\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "faiss_db = FAISS.from_documents(chunked_docs, embedding_model)\n",
    "\n",
    "# === Step 4: Save FAISS index and metadata ===\n",
    "faiss_db.save_local(\"rxnorm_faiss_index\")\n",
    "print(\"FAISS index saved to ./rxnorm_faiss_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0522a744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sebetralstat 300 MG Oral Tablet [Ekterly] (SBD) - yellow.\n",
      "{'drug_name': 'sebetralstat 300 MG Oral Tablet [Ekterly]', 'rxcui': 2717955, 'term_type': 'SBD', 'code': '2717955', 'source': 'RXNORM', 'chunk_index': 0}\n",
      "Sebetralstat 300 mg ORAL TABLET [EKTERLY] (DP) - yellow.\n",
      "{'drug_name': 'Sebetralstat 300 mg ORAL TABLET [EKTERLY]', 'rxcui': 2717955, 'term_type': 'DP', 'code': '82928-300', 'source': 'MTHSPL', 'chunk_index': 0}\n",
      "afluria 2025-2026 vaccine 0.5 ML Prefilled Syringe (PSN) - .\n",
      "{'drug_name': 'afluria 2025-2026 vaccine 0.5 ML Prefilled Syringe', 'rxcui': 2718400, 'term_type': 'PSN', 'code': '2718400', 'source': 'RXNORM', 'chunk_index': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "retriever = FAISS.load_local(\"rxnorm_faiss_index\", embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "# 检索示例\n",
    "docs = retriever.similarity_search(\"what is atorvastatin\", k=3)\n",
    "for d in docs:\n",
    "    print(d.page_content)\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae312f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# --- Step 0: Setup ---\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"Missing OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "# Load FAISS retriever\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "faiss_db = FAISS.load_local(\"rxnorm_faiss_index\", embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
    "retriever = faiss_db.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Create LLM chain\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "# --- Medication + Problem helpers ---\n",
    "def extract_medications(med_str: str) -> list:\n",
    "    return [m.strip().split()[0].capitalize() for m in str(med_str).split(\",\") if m.strip()]\n",
    "\n",
    "def extract_problems(problem_str: str) -> list:\n",
    "    return [p.strip() for p in str(problem_str).split(\",\") if p.strip()]\n",
    "\n",
    "def build_prompt(med: str, context: str, problems: list) -> str:\n",
    "    return (\n",
    "        \"You are a clinical decision support assistant.\\n\"\n",
    "        \"Use the medication information and patient's problem list to identify which problem(s) the medication treats.\\n\"\n",
    "        \"If the medication is not in the knowledge base, reply 'I don’t know'.\\n\\n\"\n",
    "        f\"Medication: {med}\\n\"\n",
    "        f\"Info: {context}\\n\"\n",
    "        f\"Patient Problems: {problems}\\n\"\n",
    "        \"Which problem(s) from the list does this medication treat?\"\n",
    "    )\n",
    "\n",
    "def process_patient(row, chain) -> dict:\n",
    "    patient_id = row[\"Patient_ID\"]\n",
    "    meds = extract_medications(row.get(\"Outpatient_Medications\", \"\"))\n",
    "    problems = extract_problems(row.get(\"Past_Medical_History\", \"\"))\n",
    "\n",
    "    result = {\n",
    "        \"Patient_ID\": patient_id,\n",
    "        \"Medications\": meds,\n",
    "        \"Treated_Problems_by_Medication\": {}\n",
    "    }\n",
    "\n",
    "    for med in meds:\n",
    "        try:\n",
    "            docs = retriever.get_relevant_documents(med)\n",
    "            context = \"\\n\".join([doc.page_content for doc in docs]) if docs else \"No relevant documents found.\"\n",
    "            prompt = build_prompt(med, context, problems)\n",
    "            response = chain.run(prompt)\n",
    "            matched = [p for p in problems if p.lower() in response.lower()]\n",
    "            result[\"Treated_Problems_by_Medication\"][med] = matched\n",
    "        except Exception as e:\n",
    "            result[\"Treated_Problems_by_Medication\"][med] = f\"Error: {str(e)}\"\n",
    "\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    return result\n",
    "\n",
    "# --- Main ---\n",
    "def main():\n",
    "    df = pd.read_csv(\"chest_pain_patients.csv\")\n",
    "    df[\"Patient_ID\"] = df.index\n",
    "    results = [process_patient(row, qa_chain) for _, row in df.iterrows()]\n",
    "    final_df = pd.DataFrame(results)\n",
    "    final_df.to_csv(\"medication_problem_mapping_summary.csv\", index=False)\n",
    "    print(\"Output saved to medication_problem_mapping_summary.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
